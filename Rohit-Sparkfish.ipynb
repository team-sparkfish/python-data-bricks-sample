{"cells":[{"cell_type":"code","source":["import urllib\n\nACCESS_KEY = \"xxxxxxxxxxx\"\nSECRET_KEY = \"xxxxxxxxxxx\"\nENCODED_SECRET_KEY = urllib.quote(SECRET_KEY, \"\")\nAWS_BUCKET_NAME = \"rohit-sparkfish\"\nMOUNT_NAME = \"sparkfish\"\ndbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\ndisplay(dbutils.fs.ls(\"/mnt/sparkfish\"))"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%python\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import datediff, to_date, lit, unix_timestamp,split\nfrom pyspark.sql.types import *\n\n# Build DataFrame dataset to work with. \nformatPackage = \"csv\" if sc.version > '1.6' else \"com.databricks.spark.csv\"\ndf = sqlContext.read.format(formatPackage).options(header='true', delimiter = ',').load(\"dbfs:/mnt/sparkfish/titanic.csv\")\ndata_df=df.withColumn(\"Age\", df[\"Age\"].cast(IntegerType()))\ndata_df.printSchema()\ndata_df.write.saveAsTable('sparkfishTable', format='parquet', mode='overwrite',path='dbfs:/mnt/sparkfish/sparkfishTable/')"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark import SparkContext, HiveContext\nhiveContext = HiveContext(sc)\ndisplay(hiveContext.sql(\"SELECT percentile(Age, 0.75) FROM sparkfishTable\"))\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark import SparkContext, HiveContext\nhiveContext = HiveContext(sc)\ndisplay(hiveContext.sql(\"SELECT avg(Age) FROM sparkfishTable\"))"],"metadata":{},"outputs":[],"execution_count":4}],"metadata":{"name":"Rohit-Sparkfish","notebookId":232751078762578},"nbformat":4,"nbformat_minor":0}
